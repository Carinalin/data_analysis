{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python实例练习：用户行为模式分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.数据来源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 本次项目基于天池公开数据，通过对相关指标进行用户行为分析\n",
    "* 数据文件下载地址：https://tianchi.aliyun.com/dataset/dataDetail?dataId=20317"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.分析目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.计算日PV、日UV\n",
    "* 2.付费率情况\n",
    "* 3.复购率情况\n",
    "* 4.构建漏斗模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.数据简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* user_id：用户ID，数据已脱敏\n",
    "* item_id：商品ID，数据已脱敏\n",
    "* behavior_type：行为类型,共有4类，包括点击、收藏、加购物车、支付等4种行为，分别用数字1、2、3、4表示）\n",
    "* user_geohash：地理位置\n",
    "* item_category：品类ID,即商品所属品类\n",
    "* time：发生时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入相关数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks\n",
    "from plotly.offline import iplot,init_notebook_mode\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.读取数据并理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无参数导入csv文件发现user_id等4个字段的数据类型为int，因此，导入时直接全部设为string。\n",
    "data=pd.read_csv('tianchi_fresh_comp_train_user.csv',encoding=\"utf-8\",dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>behavior_type</th>\n",
       "      <th>user_geohash</th>\n",
       "      <th>item_category</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001082</td>\n",
       "      <td>285259775</td>\n",
       "      <td>1</td>\n",
       "      <td>97lk14c</td>\n",
       "      <td>4076</td>\n",
       "      <td>2014-12-08 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001082</td>\n",
       "      <td>4368907</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5503</td>\n",
       "      <td>2014-12-12 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001082</td>\n",
       "      <td>4368907</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5503</td>\n",
       "      <td>2014-12-12 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001082</td>\n",
       "      <td>53616768</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9762</td>\n",
       "      <td>2014-12-02 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001082</td>\n",
       "      <td>151466952</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5232</td>\n",
       "      <td>2014-12-12 11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id    item_id behavior_type user_geohash item_category           time\n",
       "0  10001082  285259775             1      97lk14c          4076  2014-12-08 18\n",
       "1  10001082    4368907             1          NaN          5503  2014-12-12 12\n",
       "2  10001082    4368907             1          NaN          5503  2014-12-12 12\n",
       "3  10001082   53616768             1          NaN          9762  2014-12-02 15\n",
       "4  10001082  151466952             1          NaN          5232  2014-12-12 11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23291027, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23291027 entries, 0 to 23291026\n",
      "Data columns (total 6 columns):\n",
      "user_id          object\n",
      "item_id          object\n",
      "behavior_type    object\n",
      "user_geohash     object\n",
      "item_category    object\n",
      "time             object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id          0.000000\n",
       "item_id          0.000000\n",
       "behavior_type    0.000000\n",
       "user_geohash     0.683139\n",
       "item_category    0.000000\n",
       "time             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#统计缺失率\n",
    "data.apply(lambda x:np.sum(x.isnull())/len(x),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出：user_geohash的字段存在缺失值，且缺失率高达68.3%。因本次分析目的不涉及地理位置，为提高数据处理效率，删除该字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('user_geohash',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.重复值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除整行相同的重复数据\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.增加新变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间字段的处理\n",
    "data['time']=pd.to_datetime(data['time'],errors='coerce')\n",
    "data['time'].head()\n",
    "data['date']=pd.to_datetime(data['time'].dt.date,errors='coerce')\n",
    "data['hour']=data['time'].dt.hour.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress= True)\n",
    "pd.set_option('display.float_format',lambda x: '%.2f'% x)#设置数据的显示为浮点型。\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 数据中除了时间变量外，其余5个变量均为字符串字段，可以看出数据无异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.pv和uv分析\n",
    "* pv：页面访问量，页面被刷新一次就计算一次\n",
    "* uv：访客访问量，访问网站的一个客户端为一个访客"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.日期变化特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算日pv\n",
    "pv_daily=data.groupby('date').count()[['user_id']].rename(columns={'user_id':'pv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算日uv:排除用户一天多次登录的情况\n",
    "uv_daily=data.groupby('date')[['user_id']].apply(lambda x: x.drop_duplicates().count())\\\n",
    ".rename(columns={'user_id':'uv'})\n",
    "# 去重值计算也可以写成data.groupby('date').nunique()[['user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将日pv和日uv合并在一起\n",
    "pv_uv_daily=pd.merge(left=pv_daily,right=uv_daily,how='outer',left_index=True ,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算两者的相关系数\n",
    "corr_pv_uv_daily=pv_uv_daily.corr(method='pearson')\n",
    "print('日pv和日uv的相关系数为：%.2f'% corr_pv_uv_daily.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算独立访客日平均浏览量\n",
    "pv_uv_daily['ratio']=pv_uv_daily['pv']/pv_uv_daily['uv']\n",
    "print(pv_uv_daily[['ratio']].describe())\n",
    "pv_uv_daily['ratio'].iplot(mode='lines+markers',\n",
    "    opacity=0.8,\n",
    "    size=8,\n",
    "    symbol=1,\n",
    "    xTitle='Date',\n",
    "    yTitle='pv/uv',\n",
    "    title='pv/uv over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日pv和日uv数据可视化\n",
    "pv_uv_daily[['pv','uv']].iplot(mode='lines+markers',\n",
    "    opacity=0.8,\n",
    "    size=8,\n",
    "    symbol=1,\n",
    "    xTitle='Date',\n",
    "    yTitle='pv',\n",
    "    secondary_y = 'uv',\n",
    "    secondary_y_title='uv',\n",
    "    title='pv and uv over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可以看出：\n",
    "* 1、日pv和日uv关系密切，相关系数为0.93，升降趋势相同。\n",
    "* 2、双十二期间，日pv和日uv均达到峰值，当天用户最为活跃，平均一个独立访客打开页面44次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.时间变化特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算小时pv\n",
    "pv_hour=data.groupby('hour').count()[['user_id']].rename(columns={'user_id':'pv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算小时uv\n",
    "uv_hour=data.groupby('hour').nunique()[['user_id']].rename(columns={'user_id':'uv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将小时pv和小时uv合并在一起\n",
    "pv_uv_hour=pd.merge(left=pv_hour,right=uv_hour,how='outer',left_index=True ,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算两者的相关系数\n",
    "corr_pv_uv_hour=pv_uv_hour.corr(method='pearson')\n",
    "print('小时pv和小时uv的相关系数为：%.2f'% corr_pv_uv_hour.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算独立访客小时平均浏览量\n",
    "pv_uv_hour['ratio']=pv_uv_hour['pv']/pv_uv_hour['uv']\n",
    "print(pv_uv_hour[['ratio']].describe())\n",
    "pv_uv_hour['ratio'].iplot(mode='lines+markers',\n",
    "    opacity=0.8,\n",
    "    size=8,\n",
    "    symbol=1,\n",
    "    xTitle='Date',\n",
    "    yTitle='pv/uv',\n",
    "    title='pv/uv over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小时pv和小时uv数据可视化\n",
    "pv_uv_hour[['pv','uv']].iplot(mode='lines+markers',\n",
    "    opacity=0.8,\n",
    "    size=8,\n",
    "    symbol=1,\n",
    "    xTitle='Date',\n",
    "    yTitle='pv',\n",
    "    secondary_y = 'uv',\n",
    "    secondary_y_title='uv',\n",
    "    title='pv and uv over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可以看出：\n",
    "* 0点-5点期间，pv和uv同步下降，用户活跃度降低。\n",
    "* 5点-10点期间，uv急剧上升，大部分用户已经激活，但用户行为不活跃，访问量较低。\n",
    "* 晚上18点之后，pv急剧上升，并在22点达到峰值，说明晚上是用户访问的活跃时间段。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.不同行为类型的pv分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_detail=pd.pivot_table(data=data,\n",
    "    values='user_id',\n",
    "    index='hour',\n",
    "    columns='behavior_type',\n",
    "    aggfunc=np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_detail[['1', '2', '3','4']].iplot(\n",
    "    mode=\"lines\",\n",
    "    opacity=0.8,\n",
    "    size=8,\n",
    "    symbol=1,\n",
    "    secondary_y = ['2','3','4'],\n",
    "    xTitle='hour',\n",
    "    title='behavior_type and pv over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可以看出：\n",
    "* 1、四种用户行为的波动情况和pv的整体波动情况基本一致。\n",
    "* 2、点击（1）这一行为的pv访问量远高于其他三种用户行为，之后依次是加购物车（3）、收藏（2）、支付（4）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.用户消费行为分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.用户购买次数分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy=data[data['behavior_type']=='4'].groupby('user_id').size()\n",
    "print(data_buy.describe())\n",
    "print(data_buy.quantile([0.7,0.8,0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_buy[data_buy.values>10])/sum(data_buy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy.iplot(\n",
    "    kind='hist',\n",
    "    bins=100,\n",
    "    xTitle='purchase times',\n",
    "    linecolor='black',\n",
    "    histnorm='percent',\n",
    "    yTitle='percentage (%)',\n",
    "    title='User purchase times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可知：\n",
    "* 1、一半的用户消费次数低于8次，80%的用户消费次数低于17次,但位于金字塔顶端20%的用户消费次数最多可达331次，应对该部分高粘性用户实行特定的粘性政策。\n",
    "* 2、消费次数高于10次的用户贡献了3/4的总消费数，应重点关注该部分用户的维护。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.分析ARPPU\n",
    "* ARPPU(average revenue per paying user):即从每个付费用户身上得到的收入。\n",
    "* ARPPU=total revenue/user number\n",
    "* 因为表中没有用户消费金额，因此采用消费次数代替消费金额。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个用户每天的消费次数\n",
    "data_buy_user=data[data['behavior_type']=='4'].groupby(['date','user_id'])['behavior_type'].count().reset_index().rename(columns={'behavior_type':'消费次数'})\n",
    "data_buy_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日人均消费次数=日销售总次数/日消费人数\n",
    "data_buy_per=pd.DataFrame(data_buy_user.groupby('date').sum()['消费次数']/\\\n",
    "                          data_buy_user.groupby('date').count()['消费次数']).rename(columns={'消费次数':'日均消费次数'})\n",
    "data_buy_per.insert(0,'日销售总次数',data_buy_user.groupby('date').sum()['消费次数'])\n",
    "data_buy_per.insert(1,'日消费人数',data_buy_user.groupby('date').count()['消费次数'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy_per.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy_per['日均消费次数'].iplot(mode='lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可以得出：\n",
    "* 用户每日消费次数在1-2之间波动，但在双十二期间达到峰值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.复购情况分析\n",
    "* 复购情况：即两天以上有购买行为，一天多次购买算一次。\n",
    "* 复购率=有复购行为的用户数/有购买行为的用户总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rebuy=data[data['behavior_type']=='4'].groupby('user_id')[['date']].apply(lambda x: x.nunique()).\\\n",
    "            rename(columns={'date':'rebuy_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算复购率\n",
    "print('一个月内复购率为：',round(data_rebuy[data_rebuy['rebuy_count']>=2].count()\\\n",
    "                        /data_rebuy.count(),2).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看一下复购率情况\n",
    "data_rebuy.iplot(kind='hist',bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 这里的分析结果其实和4.2.1.用户购买次数分析中一致，不再赘述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有复购时间间隔消费次数分析\n",
    "data_buy_user3=data[data.behavior_type=='4'].groupby(['user_id','date']).behavior_type.count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy_user3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用差分函数diff计算每个用户每次的时间间隔\n",
    "data_buy_user3=data_buy_user3.groupby('user_id')['date'].apply\\\n",
    "              (lambda x: x.sort_values().diff(1).dropna()).map(lambda x: x.days)\n",
    "data_buy_user3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "data_buy_user3.value_counts().iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可知：\n",
    "* 大多数付费用户在1-5天之内复购，相隔10天以上复购的用户很少，说明用户对APP的忠诚度和需求度较高。\n",
    "* 用户对APP的复购需求大，因此应重视在10天之内激活用户复购。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(data_buy_user3.reset_index().groupby('user_id').date.mean().describe())\n",
    "sns.distplot(data_buy_user3.reset_index().groupby('user_id').date.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 不同用户平均复购时间接近正态分布，以4作为峰值，向两边呈下降趋势。\n",
    "* 大部分用户平均复购时间集中在1-6天内。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.漏斗流失分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processing=data['behavior_type'].value_counts()\n",
    "data_all=data['behavior_type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('behavior_type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算各个环节的流失率（收藏不是必要的用户行为，故不纳入分析）\n",
    "print('浏览-点击：流失率等于%.2f%%'%(((data_all-data_processing[0])*100)/data_all))\n",
    "print('点击-加入购物车：流失率等于%.2f%%'%(((data_processing[0]-data_processing[2])*100)/data_processing[0]))\n",
    "print('加入购物车-支付：流失率等于%.2f%%'%(((data_processing[2]-data_processing[3])*100)/data_processing[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上分析可以得知：\n",
    "* 点击-加入购物车的流失率非常高，说明用户在浏览时被封面吸引进行点击，但商品的具体介绍部分无法进一步吸引顾客。\n",
    "* 因此，需要重视该环节的优化，做好商品的具体展示。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
